{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 1. Using `BaseModel` (Pydantic)\n",
    "\n",
    "### What this method is\n",
    "\n",
    "You define a Pydantic model (`Country(BaseModel)`) and pass the class to `llm.with_structured_output(Country)`.\n",
    "LangChain uses the model’s type hints + field metadata to:\n",
    "\n",
    "- Build a JSON schema behind the scenes\n",
    "- Validate / parse the LLM response into a **real Python object** of type `Country`\n",
    "\n",
    "### Things to remember\n",
    "\n",
    "- **Strong validation**:\n",
    "  - Types are enforced (`str`, `int`, `float`, etc.)\n",
    "  - Missing / extra fields are checked and can raise validation errors.\n",
    "- **Best when you want Python objects as the final result**:\n",
    "  - e.g. `country.name`, `country.language`, `country.capital` with autocomplete in your IDE.\n",
    "- **Good for bigger / reusable schemas**:\n",
    "  - You can reuse the Pydantic model anywhere else in your project (DB models, API schemas, etc.).\n",
    "- You can add defaults, regex, `Field(..., description=\"...\")`, etc. to control both docs and validation.\n",
    "- Slightly **heavier dependency**: relies on Pydantic, but that’s standard in many Python projects.\n",
    "\n",
    "### When to use\n",
    "\n",
    "- You want **strict structure + validation**.\n",
    "- You want **Pythonic, IDE-friendly** objects.\n",
    "- You already use Pydantic in FastAPI / other parts of your code.\n"
   ],
   "id": "a70fa9b12bdc3d28"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-09T09:32:07.287895900Z",
     "start_time": "2025-12-09T09:32:07.242145300Z"
    }
   },
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-flash-lite-latest\")\n",
    "\n",
    "class Country(BaseModel):\n",
    "\n",
    "    \"\"\"Information about a country\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"name of the country\")\n",
    "    language: str = Field(description=\"language of the country\")\n",
    "    capital: str = Field(description=\"Capital of the country\")\n",
    "\n",
    "structured_llm = llm.with_structured_output(Country)\n",
    "structured_llm"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGoogleGenerativeAI(model='models/gemini-flash-lite-latest', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000002180D702690>, default_metadata=()), kwargs={'tools': [{'type': 'function', 'function': {'name': 'Country', 'description': 'Information about a country', 'parameters': {'properties': {'name': {'description': 'name of the country', 'type': 'string'}, 'language': {'description': 'language of the country', 'type': 'string'}, 'capital': {'description': 'Capital of the country', 'type': 'string'}}, 'required': ['name', 'language', 'capital'], 'type': 'object'}}}]}, config={}, config_factories=[])\n",
       "| PydanticToolsParser(first_tool_only=True, tools=[<class '__main__.Country'>])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T09:00:49.286732100Z",
     "start_time": "2025-12-09T09:00:48.008682200Z"
    }
   },
   "cell_type": "code",
   "source": "structured_llm.invoke(\"Tell me about Sri Lanka\")",
   "id": "8123c507b55190e6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country(name='Sri Lanka', language='Sinhala', capital='Sri Jayawardenepura Kotte')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2. Using `TypedDict` + `Annotated`\n",
    "\n",
    "### What this method is\n",
    "\n",
    "You create a `TypedDict` (`class Joke(TypedDict)`) and use `Annotated` to attach descriptions to each key.\n",
    "Passing `Joke` into `llm.with_structured_output(Joke)` lets LangChain:\n",
    "\n",
    "- Generate a JSON schema from the `TypedDict` + `Annotated` info\n",
    "- Return a **plain Python `dict`** that matches your type hints\n",
    "\n",
    "### Things to remember\n",
    "\n",
    "- **Lighter-weight than Pydantic**:\n",
    "  - No Pydantic dependency, just standard typing tools.\n",
    "- Still gives **type information**:\n",
    "  - Great for static type checkers (mypy, pyright) and IDE autocomplete.\n",
    "- `Annotated[type, default, \"description\"]` is interpreted as:\n",
    "  - The base type (`str`, `int`, etc.)\n",
    "  - An optional default (often `...` is used as “no default”)\n",
    "  - A human-readable description for schema / docs.\n",
    "- **No runtime validation like Pydantic**:\n",
    "  - It’s mostly for schema generation + editor help, not strict validation.\n",
    "\n",
    "### When to use\n",
    "\n",
    "- You want **lightweight structured output** with minimal dependencies.\n",
    "- You’re okay with **dicts instead of full model objects**.\n",
    "- You care about **type hints + nice autocomplete**, but heavy validation is not critical.\n"
   ],
   "id": "82b5549390402c34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T09:31:36.182092400Z",
     "start_time": "2025-12-09T09:31:34.909500700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-flash-lite-latest\")\n",
    "\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "# TypedDict\n",
    "class Joke(TypedDict):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    setup: Annotated[str,..., \"The setup of the joke\"]\n",
    "\n",
    "    # Alternatively, we could have specified setup as:\n",
    "\n",
    "    # setup: str                    # no default, no description\n",
    "    # setup: Annotated[str, ...]    # no default, no description\n",
    "    # setup: Annotated[str, \"foo\"]  # default, no description\n",
    "\n",
    "    punchline: Annotated[str,..., \"The punchline of the joke\"]\n",
    "    rating: Annotated[Optional[int], None,\"How funny the joke is, from 1 to 10\"]\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(Joke)\n",
    "\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ],
   "id": "79f56d45892f3a32",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'args': {'punchline': 'Because they always land on their feet!',\n",
       "   'setup': 'Why are cats so good at video games?'},\n",
       "  'type': 'Joke'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 3. Using a raw JSON Schema dict\n",
    "\n",
    "### What this method is\n",
    "\n",
    "You manually write a JSON schema dictionary (with `type`, `properties`, `required`, etc.) and pass it to:\n",
    "```python\n",
    "structured_llm = llm.with_structured_output(json_schema)\n"
   ],
   "id": "af1f9fe14adbe38a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T09:36:30.777841400Z",
     "start_time": "2025-12-09T09:36:29.656893600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-flash-lite-latest\")\n",
    "\n",
    "json_schema = {\n",
    "    \"title\": \"joke\",\n",
    "    \"description\": \"Joke to tell user.\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"setup\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The setup of the joke\",\n",
    "        },\n",
    "        \"punchline\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The punchline to the joke\",\n",
    "        },\n",
    "        \"rating\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"How funny the joke is, from 1 to 10\",\n",
    "            \"default\": None,\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"setup\", \"punchline\"],\n",
    "}\n",
    "structured_llm = llm.with_structured_output(json_schema)\n",
    "\n",
    "structured_llm.invoke(\"Tell me a joke about cats\")"
   ],
   "id": "adb16d694bd6ff14",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'args': {'punchline': 'He was a purr-fessional.',\n",
       "   'setup': 'Why did the cat get a job at the bank?'},\n",
       "  'type': 'joke'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
